# Процессор
**Центральный процессор** — это мозг компьютера, его задача — выполнять программы. Для этого он вызывает команды из памяти, определяет их тип, а затем выполняет одну за другой. 

Компоненты соединены шиной, представляющей собой набор параллельно связанных проводов для передачи адресов, данных и управляющих сигналов. Шины могут быть внешними (связывающими процессор с памятью и устройствами ввода-вывода) и внутренними.

**Процессор состоит из нескольких частей**. 
1. **Блок управления** отвечает за вызов команд из памяти и определение их типа. 
2. **Арифметико-логическое устройство(АЛУ)** выполняет арифметические и логические операции.
3. **Регистры** - память быстрого доступа(поскольку они находятся внутри процессора) в которой находятся значения с которыми в данный момент работает процессор и инструкции.

Самый важный регистр — **счетчик команд**, который указывает, какую команду нужно выполнять следующей. В **регистре команд** находится выполняемая в данный момент команда. У большинства компьютеров имеются и другие регистры.

# Устройство центрального процессора
![](ALU.png)

Тракт данных состоит из регистров($1-32$), арифметика-логического устройства(АЛУ) и нескольких соединительных шин. Содержимое регистров поступает на вход АЛУ(A and B), в этих регистрах хранятся данные, пока АЛУ производят вычисления.

АЛУ выполняет сложение, вычитание и другие простые операции над входными данными и помещает результат в выходной регистр. Содержимое этого выходного регистра может записываться обратно в один из регистров или сохраняться в памяти, если это необходимо.

**Слова** - это элементы данных, которые перемещаются между памятью и регистрами. Словом может быть целое число. Размер слова обычно соответствует разрядности регистра данных, у 32-разрядных микропроцессоров - 32 бита.

Большинство команд можно разделить на две группы:

1. Команды типа **регистр-память** - вызывают слова из памяти, помещают их в регистры, где они используется как входные данные АЛУ. Другие команды этого типа помещают регистры обратно в память.
2. Команды типа **регистр-регистр** - вызывают два операнда из регистров, помещают их во входные регистры АЛУ, выполняют над ними какую-нибудь арифметическую или логическую операцию и переносят результат обратно в один из регистров. Этот процесс называется **циклом тракта данных**.

Современные компьютеры оснащаются несколькими АЛУ, работающими параллельно и специализирующимися на разных функциях. Чем быстрее происходит цикл тракта данных, тем быстрее компьютер работает.

# Выполнение команд
Центральный процессор выполняет каждую команду за несколько шагов:

1. Вызывает следующую команду из памяти и переносит ее в регистр команд
2. Меняет положение счетчика команд, который после этого указывает на следующую команду. Это происходит после декодирования команды, а иногда и после ее выполнения.
3. Определяет тип вызванной команды.
4. Если команда использует слово из памяти, определяет, где находится слово
5. Переносит слово, если это необходимо, в регистр центрального процессора.
6. Выполняет команду.
7. Переходит к шагу 1, чтобы начать выполнение следующей команды

Такая последовательность шагов (выборка — декодирование — исполнение) является основой работы всех компьютеров.

# Системы RISC и CISC
RISC (Reduced Instruction Set Computer — компьютер с сокращенным набором команд) противопоставлялся системе CISC (Complex Instruction Set Computer — компьютер с полным набором команд)

Суть RISC компьютеров - включение туда небольшого количества простых команд каждая из которых выполняется за один **цикл тракта данных**.

Сторонники **RISC** обуславливали преимущества данной архитектуры тем, что если  придется выполнять 4-5 команд вместо одной, которую выполняет **CISC**, **RISC** все равно выигрывает в скорости, т.к. RISC-команды выполняются в 10 раз быстрее(поскольку они не интерпретируются)

Почему с RISC было не все так хорошо?

* Компьютеры RISC несовместимы с другими моделями.
* Intel сумела воплотить те же идеи в архитектуре **CISC**. Процессоры Intel, начиная с процессора 486, содержат RISC-ядро, которое выполняет самые простые (и обычно самые распространенные) команды за один цикл тракта данных, а по обычной технологии **CISC** интерпретируются более сложные команды. В результате обычные команды выполняются быстро, а более сложные и редкие — медленно. 

Хотя при таком «гибридном» подходе производительность ниже, чем в архитектуре RISC, новая архитектура CISC имеет ряд преимуществ, поскольку позволяет использовать старое программное обеспечение без изменений.

# Параллелизм на уровне команд
Для повышения производительности процессора разработчики используют параллелизм(выполнение двух или более операций одновременно). Параллелизм на уровне команд реализуется за счет запуска большого количества команд каждую секунду.

## Конвейеры
Препятствием высокой производительности является загрузка команд из памяти. Решение - заранее их выгружать и хранить в наборе регистров, **буфере выборки с упреждением**, т.е. когда нужна была команда она вызывалась из буфера, а обращение к памяти не происходило.

При выборке с упреждением команда обрабатывается в 2 шага:

1. происходит выборка команды
2. выполнение команды

Данная стратегия стала концепцией конвейера. При использовании конвейера команда обрабатывается за большее количество шагов, каждый из которых реализуется определенным аппаратным компонентом, причем все эти компоненты могут работать параллельно.

![ ](c1c2c3c4c5.png)

* C1 - вызывает команду из памяти и помещает ее в буфер, где она хранится до тех пор, пока не потребуется
* С2 - декодируется команду, определяя ее тип и тип ее операндов
* С3 - определяет местонахождение операндов и вызывает их из регистров или из памяти
* С4 - выполняет команду, обычно проводя операнды через **тракт данных**
* С5 - записывает результат обратно в нужный регистр

![[../Files/conveyor 1.gif]]

* Цикл 1 - блок C1 обрабатывает команду 1, вызывая ее из памяти
* Цикл 2 - блок C2 декодирует команду 1, C1 вызывается из памяти команду 2
* Цикл 3 - блок C3 вызывает операнды для команды 1, C2 декодирует команду 2, C1 - вызывает команду 3
* Цикл 4 - блок C4 выполняет команду 1, C3 вызывает операнды для команды 3, C2 декодирует команду 3, C1 вызывает команду 4
* Цикл 5 - блок C5 записывает результат выполнения команды 1 обратно в регистр, другие ступени конвейера обрабатывают следующие команды

## Супер скалярные архитектуры
Два конвейера вместо одного. Один блок выборки команд вызывает из памяти по 2 команды. Каждый конвейер содержит АЛУ для параллельных операций. Чтобы выполняться параллельно, две команды не должны конфликтовать из-за ресурсов (например, регистров) и ни одна из них не должна зависеть от результата выполнения другой. Как и в случае с одним конвейером, либо компилятор должен гарантировать отсутствие нештатных ситуаций (когда, например, аппаратура не обеспечивает проверку команд на несовместимость и при обработке таких команд выдает некорректный результат), либо конфликты должны выявляться и устраняться дополнительным оборудованием непосредственно в ходе выполнения команд.

![](twoconveyor.png)

## Yet another супер скалярная архитектура
Один конвейер с большим количеством функциональных блоков.

![](super_scalyar.png)

Со временем определение «супер скалярности» несколько изменилось. Теперь супер скалярными называют процессоры, способные запускать несколько команд (от четырех до шести) за один тактовый цикл. Естественно, для передачи всех этих команд в супер скалярном процессоре должно быть несколько функциональных блоков. 

# Параллелизм на уровне процессоров
Параллелизм на уровне процессоров реализуется за счет того, что над одним заданием работают одновременно несколько процессоров. Параллелизм на уровне команд помогает, но конвейеры и суперскалярная архитектура обычно повышают скорость работы всего лишь в 5–10 раз. Чтобы увеличить производительность в 50, 100 и более раз, нужно создавать компьютеры с несколькими процессорами.

## Мультипроцессоры
Система из нескольких параллельных процессоров, имеющих общую память, называется **мультипроцессором.** 

Поскольку каждый процессор может записывать информацию в любую часть памяти и считывать информацию из любой части памяти, чтобы не допустить каких-либо нестыковок, их работа должна согласовываться программным обеспечением. В ситуации, когда два или несколько процессоров имеют возможность тесного взаимодействия, а именно так происходит в случае с мультипроцессорами, эти процессоры называют **сильно связанными (tightly coupled)**.

Возможны разные способы воплощения этой идеи.

![](mult.png)

1. Соединение единственной шиной нескольких процессоров и общей памяти. Способ простой, но минус в том, что процессоры могут обращаться к общей памяти, что может тормозить работу
2. Процессор имеет собственную локальную память, недоступную для других процессоров. Эта память используется для тех программ и данных, которые не нужно разделять между несколькими процессорами. При обращении к локальной памяти основная шина не используется, и, таким образом, объем передаваемой по ней информации становится меньше.

## Мульти компьютеры
Мультипроцессоры с небольшим числом процессоров $≤256$ разрабатывать просто, но создание больших мультипроцессоров представляет трудности. Сложность заключается в том, чтобы связать все процессоры с общей памятью. Поэтому многие разработчики отказались от идеи разделения памяти и стали создавать системы без общей памяти, состоящие из большого числа взаимосвязанных компьютеров, у каждого из которых имеется собственная память. Такие системы называются **мульти компьютерами**. В них процессоры являются **слабо связанными**.