# Operating system and computer architecture
Большинство компьютеров имеют **2 режим работы: режим ядра и режим суперпользователя**.

**[[Операционная система]]** работает в режиме ядра, благодаря которому имеет полный доступ ко всему **[[Аппаратное обеспечение|аппаратному обеспечению]]** и может задействовать любые машинные инструкции. Вся остальная часть ПО работает в режиме пользователя и может использовать только подмножество машинных инструкций(к примеру они не могут осуществлять ввод/вывод, но могут запросить у ОС разрешение на это).

# Для чего нужна OS
Архитектура большинства компьютеров примитивна и не удобна(все что может компьютер это складывать и перемещать биты). Для более упрощенной работой с ним, придумали такую прослойку, как Операционная система. 

OS обеспечивает:
1. Доступ к устройствам - клавиатура, мышь и др.
2. Работу с файлами
3. Создание и взаимодействие процессов
4. Мониторинг ресурсов, время, отладка

Управление ресурсами включает в себя распределение ресурсов двумя различными способами:
1. Во времени - т.е. различные программы пользуются им по очереди - для этого операционной системе есть [[Процессы]].
2. В пространстве - т.е. вместо поочередной работы устройство получает часть ресурса, к примеру часть оперативной памяти. Таким образом, в ней может храниться несколько программ.

# Нужное
[Direct Mapping — Map cache and main memory](https://medium.com/breaktheloop/direct-mapping-map-cache-and-main-memory-d5e4c1cbf73e)
[Direct-Mapped Cache and its architecture](http://www.mathcs.emory.edu/~cheung/Courses/355/Syllabus/8-cache/dm.html)

# stepik
![[../Files/Pasted image 20220504104336.png]]

![[../Files/Pasted image 20220504104620.png]]

![[retq.png]]

![[../Files/Pasted image 20220504123924.png]]

![[../Files/Pasted image 20220504132355.png]]

Как происходит преобразование? ОС проверяет, что мы не вышли за границы нашего пространства, отступает на Base, это будет начало нашего пространства.





Способ организации виртуальной памяти, при котором виртуальные адреса отображаются на физические постранично (обычно 1 страница = 4 КB).

Память процесса может лежать в физической памяти в любом порядке:

![[adrr.excalidraw]]

Адресация реализуется через _PageTables_.

Если у нас страницы имеют размер 4 КБ, а физической памяти всего 4 ГБ, то мы можем создать 1 миллион страниц, то есть у нас будет массив из миллиона элементов. Вместо массива на много элементов мы храним массив (_каталог страниц_) размера 1024 из указателей на массивы размерами по 1024 (_таблицы страниц_). Почему это удобнее? Некоторые указатели на таблицы можно не хранить, если память не используется.

Это выглядит как-то так:
![](02.15_page_table.png)
![](02.15_page_tables.png)

Значение регистра CR3 для каждой программы свой, т.к. у них разные адресные пространства. Для ускорения трансляции виртуального в физический применяется специальный кеш TLB (Translation lookaside buffer). Так же, как и обычный, может быть нескольких уровней.


# Кэш-память
```cpp
for i = 0..n:				for i=0..n:
    for j=0..n:				for j=0..n:
        a[i][j] = 0 				a[j][i] = 0

```
У этих двух кодов большая разница из-за процессорного кэша. Первый цикл обращается к памяти последовательно, а второй "скачет" по ней. Поэтому обращения к памяти первого цикла попадают в кэш, а второго - нет. С ростом **N** видна разница между уровнями кэша на графике времени обработки одного элемента:
![](02.29_cache_hit_graph.png)
![[../Files/Pasted image 20220517153333.png]]

Небольшие пики - скачки из-за попадания в один бакет (заметно на степенях двойки), сильное изменение времени работы происходит, когда данные перестают попадать в кэш какого-то уровня.

**Кэш** реализован через хэш-таблицы (дискретного размера), где ключ - адрес в памяти. Линии кэша примерно по _64 байта_ разделенные на группы (buckets), размеры которых называются ассоциативностью кэша.

**Prefetching** - если много кэш-промахов, запрашиваем заранее подгрузить в кэш. Это работает на уровне кэш-подсистемы процессора, а не компилятора/ОС.

_Пример_: хранение хэш-таблицы с открытой адресацией. Два варианта:
![](02.29_hash_table.png)
-   Если ожидаются частые попадания, то хранить полезнее данные рядом с ключом.
-   Если ожидаются редкие попадания, то лучше хранить ключи и данные отдельно.

# Конвейер (Pipelining)
Разбили выполнение команды на несколько стадий, теперь можем повысить частоту, так как каждая стадия стала проще. Выигрыш в том, что можем давать новые данные на каждом такте.

**Спекулятивное исполнение**: условные переходы дорогие, поэтому мы предсказываем переход, выполняем, а если не угадали, то откатываемя. В общем, ничего нового. Также это называется **branch prediction**. Можем как выиграть, так и проиграть от этого. Например, [в некоторых программах на отсортированном массиве](https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array) предсказание может улучшить время работы в несколько раз.

Полезно писать программу так, чтобы уровень зависимостей команд был как можно меньше (это может также пытаться делать компилятор). Например:

`int f(int a, int b, int c, int d) {  return a * b * c * d; }`

может скомпилиться в следующий код, чтоб уменьшить количество зависимых умножений: $(a * b) * (c * d)$
```asm
 imul edi, esi
 imul edx, ecx  
 imul edx, edi  
 mov	 eax, edx  
 ret
```

Похожее происходит с циклами. Посмотрим на алгоритм Хаффмана:
```cpp
void count_huffman_weights(char const* src, size_t size) {      
	uint32_t count[256] = {0};      
	for (size_t i = 0; i != size; ++i)          
		++count[src[i]]; 
}
```


может быть разбит компилятором на параллельные исполнения. Так будут выглядеть зависимости:

![](02.29_dependencies.png)

Но у нас возникают проблемы из-за того, что мы пишем в одни переменные. Как пофиксить? Можем сделать 8 разных массивов-счетчиков. Такая реализация используется в библиотеке **Zstandart**

```cpp
void count_huffman_weights_improved(char const* src, size_t size) {  
	uint32_t count[8][256] = {};  
	size = size / 8 * 8;  
	for (size_t i = 0; i < size;){            
		++count[0][src[i++]]; ++count[1][src[i++]]; ++count[2][src[i++]];            
		++count[3][src[i++]]; ++count[4][src[i++]]; ++count[5][src[i++]];            
		++count[6][src[i++]]; ++count[7][src[i++]];      
	} 
}
```