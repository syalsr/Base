# Operating system and computer architecture
Большинство компьютеров имеют **2 режим работы: режим ядра и режим суперпользователя**.

**[[Операционная система]]** работает в режиме ядра, благодаря которому имеет полный доступ ко всему **[[Аппаратное обеспечение|аппаратному обеспечению]]** и может задействовать любые машинные инструкции. Вся остальная часть ПО работает в режиме пользователя и может использовать только подмножество машинных инструкций(к примеру они не могут осуществлять ввод/вывод, но могут запросить у ОС разрешение на это).

# Для чего нужна OS
Архитектура большинства компьютеров примитивна и не удобна(все что может компьютер это складывать и перемещать биты). Для более упрощенной работой с ним, придумали такую прослойку, как Операционная система. 

OS обеспечивает:
1. Доступ к устройствам - клавиатура, мышь и др.
2. Работу с файлами
3. Создание и взаимодействие процессов
4. Мониторинг ресурсов, время, отладка

Управление ресурсами включает в себя распределение ресурсов двумя различными способами:
1. Во времени - т.е. различные программы пользуются им по очереди - для этого операционной системе есть [[Процессы]].
2. В пространстве - т.е. вместо поочередной работы устройство получает часть ресурса, к примеру часть оперативной памяти. Таким образом, в ней может храниться несколько программ.

# Как запускается система?
1. Включаем компьютер и обращаемся по адресу 0xFFFFFFF0
2. Нам отвечает материнская плата, направляя нас в BIOS/UEFI

## BIOS
Начинает свою работу с POST - power on self test, проверяет, что все необходимые устройства в наличии и все работает, поиск загрузочного диска - это диск с которого можно прочитать первые 512 байт, последние 2 байта этого сектора должны хранить значения 0X55 и 0xAA. Этот сектор загружается в память по физическому адресу 0x7C00. После BIOS передает управления в это место.
# Нужное
* [[Linux]]
* [Direct Mapping — Map cache and main memory](https://medium.com/breaktheloop/direct-mapping-map-cache-and-main-memory-d5e4c1cbf73e)
* [Direct-Mapped Cache and its architecture](http://www.mathcs.emory.edu/~cheung/Courses/355/Syllabus/8-cache/dm.html)
* [MIT 6.004](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-004-computation-structures-spring-2017/)
* [Berkley cs61](https://inst.eecs.berkeley.edu/~cs61c/su20/)
* CMU 15-213
	* [materials]([http://www.cs.cmu.edu/afs/cs/academic/class/15213-f15/www/schedule.html](http://www.cs.cmu.edu/afs/cs/academic/class/15213-f15/www/schedule.html))
	* [video](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID="b96d90ae-9871-4fae-91e2-b1627b43e25e"&view=2&sortColumn=1&sortAscending=true&maxResults=250)
	* note
		* https://github.com/JonnyKong/CMU-15-213-Intro-to-Computer-Systems
		* https://github.com/xuwd11/15-213_labs
* [nand to tetris](https://www.nand2tetris.org)
* [virtual memory](https://www.youtube.com/playlist?list=PLiwt1iVUib9s2Uo5BeYmwkDFUh70fJPxX)
* [Berkley CS 162: Operating Systems and System Programming](https://inst.eecs.berkeley.edu/~cs162/fa20/)
* [CS 161 Computer security](https://su20.cs161.org)
* [6.S081: Operating System Engineering](https://pdos.csail.mit.edu/6.S081/2021/index.html)
* [OSTEP](https://pages.cs.wisc.edu/~remzi/OSTEP/)

# Язык Ассемблера
Для каждой архитектуры существует свой ассемблер, свой набор команд [[ISA]]

1. Инструкции копирования можно разделить на 3 типа:
	1. Память => регистр
	2. Регистр => регистр
	3. Память => память(редко)
2. Арифметические инструкции: 
	1. + 
	2. -
	3. /
	4.  *
3. Побитовые инструкции
	1. `>>`
	2. `<<`
4. Инструкции перехода, для того чтобы перейти к другому участку кода
5. А также множество специфичных инструкций

Регистры - это очень быстрые, поименованные ячейки памяти.
1. Регистры специального назначения
	1. Указатель команд IP - содержит адрес следующей инструкции или последней исполненной
	2. Флаговый регистр - хранит состояние процессора
	3. И т.д.
2. Регистры общего назначения
	1. Арифметические операции

## Далее будем говорить об архитектуре X86-64.

1. Указатель команд - RIP
2. Флаговый регистр - RFLAGS
	1. ZF = результат операции 0
	2. CF - произошло беззнаковое переполнение
	3. OF - произошло знаковое переполнение
3. Регистры общего назначения
	1. Указатель стека rsp
	2. Указатель базы(указатель стек фрейма) rbp
	3. rax, rbx, rcx; rdx, rsi, rdi; r8-r15
4. Инструкции
	1. mov - инструкция копирования, movq - q означает, что мы копируем 8 байтное значение
		1. `movq<src>, <dst>`
		2. `movq %rax, %rbx` - копируем значение rax в rbx
		3. `movq (%rax), %rax` - разыменовываем регистр rax, берем его значение, интерпретируем как адрес, идем в этот адрес и копируем в rax значение лежащее по этому адресу
		4. `movq $42, %rax` - записываем 42 в rax
		5. `movq 42, %rax` - 42 - адрес, идем по этому адресу и копируем значение в rax
	2. `addq <src>, <dst>` - складываем значения и результат сохраняем во 2 аргумент
		1. `addq %rax, %rbx` - $rbx=rax+rbx$
		2. `%rax, value` $value=rax+value$
		3. `42, %rax` $rax +=42$
	3. `subq <src>, <dst>` - вычитаем 1 аргумент из 2-го и сохраняем результат во 2 аргумент.
	4. `incq <op>` - +1 инкремент
	5. `decq <op>` - -1 декремент
	6. `mulq <op>` - умножение, в качестве 2 аргумента используется rax, старшие биты результат сохраняются в rax, младшие биты в rdx 
		1. $rax=(<op>*rax)mod2^{64}$
		2. $rdx=(<op>*rax)/2^{64}$
	7. `divq <op>` - вычисляет частное в rax и остаток от деления в rdx
		1. $rax=(rdx*2^{64}+rax)/<op>$ 
		2. $rdx=(rdx*2{64}+rax)mod<op>$
	8. `cmpq <src>, <dst>` - вычисляет разность, работает как subq, но dst не не изменяет src, dst, только RFLAGS

## Стек
Это область памяти на которую указывает rsp, в X86 стек растет вниз, т.е. чем раньше создался стековый фрейм, тем больше его адрес
1. `pushq <src>` - сдвигаем rsp на 8 байт и сохраняем src в rsp
	1. `pushq $42`
	2. `pushq %rax`
2. `popq <dst>` - удаляет значение со стека и сохраняет в dst
	1. `popq %rax`
	2. `movq (%rsp), %rax`
![[../Files/Pasted image 20220504104336.png]]
![[../Files/Pasted image 20220504104620.png]]

## Метка
Это имя которое ссылается на какой-то адрес в памяти

```asm
value:
		.quad 42 # ссылается куда-то где есть 42
add42: # указывает на начало этого кода
		movq %rdi, %rax
		...
		retq # возврат из функции
```
Чтобы куда-то вернуться нужно сохранить адрес возврата, процессор сохраняет следующий адрес которой идет после call в стек. Поэтому если мы в вызываемой функции, что-то пишем на стек, то должны очистить, иначе вернемся не туда.
![[../Files/retq.png]]
## Инструкции перехода
1. `jmp <label>` - инструкция безусловного перехода
2. `call <label` - инструкция вызова функции

## Инструкции условного перехода
1. `jcc <label>` - выполняет переход, если условие cc истинно
2. jz, je проверяет, что $ZF=1$
	1. `subq $42, %rax; je do_smth` - если $rax=42$, то выполнится переход
	2. jne, jnz - $ZF=0$
	3. jg - если больше(знаковый вариант)
	4. jge - больше или равно(знаковый вариант)
	5. ja - если больше(беззнаковый вариант)
	6. jae - больше или равно(беззнаковый вариант)

```asm
max: # поиск максимального значения в rdi и rsi
		movq %rdi, %rax
		cmpq %rsi, %rdi
		ja   rdi_get  # инструкции выполняются последовательно, если ja сработало retq
		movq %rsi, %rax # иначе будет выполнена эта функция и потом мы пойдем дальше до retq
rdi_get:
		retq
```

## ABI - Application binary interface
Это набор соглашений о:
1. Как передавать аргументы в функцию
2. Как функция возвращает значение
3. Какие регистры функция должна сохранять
4. И т.д.

Если мы собираем код разными компиляторами, они должны поддерживать одинаковый ABI

# Физическая и логическая память
Физическая - память компьютера, логическая - память приложения, приложению не нужно знать об устройстве памяти компьютера поэтому мы его так ограничиваем.

## Сегментная адресация
У нас есть таблица дескрипторов сегментов, когда создается новый процесс, ОС присваивает ему определенный дескриптор. Зная это, ОС может преобразовать логический адрес в физический.
![[../Files/Pasted image 20220504132355.png]]

Как происходит преобразование? ОС проверяет, что мы не вышли за границы нашего пространства, отступает на Base, это будет начало нашего пространства.

## Страничная адресация

Способ организации виртуальной памяти, при котором виртуальные адреса отображаются на физические постранично (обычно 1 страница = 4 КB).

Память процесса может лежать в физической памяти в любом порядке:

![[adrr.excalidraw]]

Адресация реализуется через _PageTables_.

Если у нас страницы имеют размер 4 КБ, а физической памяти всего 4 ГБ, то мы можем создать 1 миллион страниц, то есть у нас будет массив из миллиона элементов. Вместо массива на много элементов мы храним массив (_каталог страниц_) размера 1024 из указателей на массивы размерами по 1024 (_таблицы страниц_). Почему это удобнее? Некоторые указатели на таблицы можно не хранить, если память не используется.

Это выглядит как-то так:
![](02.15_page_table.png)
![](02.15_page_tables.png)

Значение регистра CR3 для каждой программы свой, т.к. у них разные адресные пространства. Для ускорения трансляции виртуального в физический применяется специальный кеш TLB (Translation lookaside buffer). Так же, как и обычный, может быть нескольких уровней.


# Кэш-память
```cpp
for i = 0..n:				for i=0..n:
    for j=0..n:				for j=0..n:
        a[i][j] = 0 				a[j][i] = 0

```
У этих двух кодов большая разница из-за процессорного кэша. Первый цикл обращается к памяти последовательно, а второй "скачет" по ней. Поэтому обращения к памяти первого цикла попадают в кэш, а второго - нет. С ростом **N** видна разница между уровнями кэша на графике времени обработки одного элемента:
![](02.29_cache_hit_graph.png)
![[../Files/Pasted image 20220517153333.png]]

Небольшие пики - скачки из-за попадания в один бакет (заметно на степенях двойки), сильное изменение времени работы происходит, когда данные перестают попадать в кэш какого-то уровня.

**Кэш** реализован через хэш-таблицы (дискретного размера), где ключ - адрес в памяти. Линии кэша примерно по _64 байта_ разделенные на группы (buckets), размеры которых называются ассоциативностью кэша.

**Prefetching** - если много кэш-промахов, запрашиваем заранее подгрузить в кэш. Это работает на уровне кэш-подсистемы процессора, а не компилятора/ОС.

_Пример_: хранение хэш-таблицы с открытой адресацией. Два варианта:
![](02.29_hash_table.png)
-   Если ожидаются частые попадания, то хранить полезнее данные рядом с ключом.
-   Если ожидаются редкие попадания, то лучше хранить ключи и данные отдельно.

# Конвейер (Pipelining)
Разбили выполнение команды на несколько стадий, теперь можем повысить частоту, так как каждая стадия стала проще. Выигрыш в том, что можем давать новые данные на каждом такте.

**Спекулятивное исполнение**: условные переходы дорогие, поэтому мы предсказываем переход, выполняем, а если не угадали, то откатываемя. В общем, ничего нового. Также это называется **branch prediction**. Можем как выиграть, так и проиграть от этого. Например, [в некоторых программах на отсортированном массиве](https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array) предсказание может улучшить время работы в несколько раз.

Полезно писать программу так, чтобы уровень зависимостей команд был как можно меньше (это может также пытаться делать компилятор). Например:

`int f(int a, int b, int c, int d) {  return a * b * c * d; }`

может скомпилиться в следующий код, чтоб уменьшить количество зависимых умножений: $(a * b) * (c * d)$
```asm
 imul edi, esi
 imul edx, ecx  
 imul edx, edi  
 mov	 eax, edx  
 ret
```

Похожее происходит с циклами. Посмотрим на алгоритм Хаффмана:
```cpp
void count_huffman_weights(char const* src, size_t size) {      
	uint32_t count[256] = {0};      
	for (size_t i = 0; i != size; ++i)          
		++count[src[i]]; 
}
```


может быть разбит компилятором на параллельные исполнения. Так будут выглядеть зависимости:

![](02.29_dependencies.png)

Но у нас возникают проблемы из-за того, что мы пишем в одни переменные. Как пофиксить? Можем сделать 8 разных массивов-счетчиков. Такая реализация используется в библиотеке **Zstandart**

```cpp
void count_huffman_weights_improved(char const* src, size_t size) {  
	uint32_t count[8][256] = {};  
	size = size / 8 * 8;  
	for (size_t i = 0; i < size;){            
		++count[0][src[i++]]; ++count[1][src[i++]]; ++count[2][src[i++]];            
		++count[3][src[i++]]; ++count[4][src[i++]]; ++count[5][src[i++]];            
		++count[6][src[i++]]; ++count[7][src[i++]];      
	} 
}
```