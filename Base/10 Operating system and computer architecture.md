# Operating system and computer architecture
Аппаратное обеспечение состоит из микросхем, плат, дисков, клавиатуры, монитора и других физических объектов. Над аппаратным обеспечением находится программное.

Большинство компьютеров имеют **2 режим работы: режим ядра и режим суперпользователя**.

[[Для чего нужна OS|Операционная система]] работает в режиме ядра, благодаря которому имеет полный доступ ко всему аппаратному обеспечению и может задействовать любые машинные инструкции. Вся остальная часть ПО работает в режиме пользователя и может использовать только подмножество машинных инструкций(к примеру они не могут осуществлять ввод/вывод, но могут запросить у ОС разрешение на это).

# Нужное
[Direct Mapping — Map cache and main memory](https://medium.com/breaktheloop/direct-mapping-map-cache-and-main-memory-d5e4c1cbf73e)
[Direct-Mapped Cache and its architecture](http://www.mathcs.emory.edu/~cheung/Courses/355/Syllabus/8-cache/dm.html)

#do/start 
1. законспектировать эти 2 статьи
2. начать проходить курсы по акосу на степике ксц
3. https://www.youtube.com/playlist?list=PLd7QXkfmSY7ZG6T7gPZ7OfAEiCwR7i8fu https://www.youtube.com/playlist?list=PLd7QXkfmSY7afUPCdL2hzDi57b8FV9EZQ как нибудь потом

# Что каждый программист должен знать о памяти?
## RAM - random access memory
Существуют 2 типа подобной памяти, статическая и динамическая RAM - SRAM и DRAM, статическая память намного быстрее динамической и предоставляет ту же функциональность, но из-за цены нам приходится использовать еще и динамическую.

Посмотрим как хранится 1 бит информации в SRAM и DRAM:

### SRAM
![[../Files/Pasted image 20220418174308.png]]

Это 6-транзисторная SRAM, ядро ячейки формируется транзисторами $M_1-M_4$, которые формируют два перекрещенных инвертера. Они имеют два стабильных состояния $0$ и $1$. Состояние остается стабильным пока подается напряжение $V_{dd}$ 

Для получения состояния подается ток на WL, сразу подается ток на $BL$ / $\overline{BL}$. Если нужно записать значение, то сначала подается ток на  $BL$ / $\overline{BL}$, а после на WL.

Итого:
1. Для одного бита информации требуется 6 транзисторов
2. Для сохранения состояния требуется постоянное наличие напряжения
3. Состояние ячейки доступно после подачи напряжения на WL.
4. Мгновенно получаем состояние ячейки

### DRAM
![[../Files/Pasted image 20220418180236.png]]
Как видно, по структуре динамическая проще статической, она состоит из одного транзистора и одного конденсатора. Она хранит свое состояние в конденсаторе $\text{C}$. Транзистор M нужен для охраны состояния, что бы прочитать состояние ячейку, подается ток на линию AL, в зависимости от наличия заряда(0/1) на линии $\text{DL}$ может появиться или не появиться ток. Что записать данные в ячейку линия $\text{DL}$ устанавливается значение, затем на $\text{AL}$ подается ток на время, достаточное для зарядки или разрядки конденсатора. 
1. Первая проблема - пользование ячейкой расходует конденсатор $=>$ его нужно постоянно перезаряжать, из-за чего доступ к памяти невозможно на десятки миллисекунд. 
2. Вторая проблема, состоит в размере заряда, из-за того что он маленький, линию должна быть подключена к усилителю, которые определяет какой это сигнал(0/1) и усиливает его.
3. Третья проблема - мы не получаем мгновенно состояние ячейки, поскольку после каждой операции его нужно перезаряжать(т.е. считать значение в усилитель, зарядить, обратно положить значение)
4. Четвертая проблема - зарядка и разрядка не происходят мгновенно.

Итог:
1. Меньше скорость получения состояние по сравнению со статической
2. Но меньший размер на плате
3. К тому же, каждый транзистор нужно питать, у статической их целых 6.

## Cache
Как мы уже поняли, доступ к памяти занимает какое-то время, во время которого процессор простаивает, для лучше работоспособности придумали кэш, память которая находится рядом с процессором.

![[../Files/Pasted image 20220419041047.png]]

Какие есть варианты использования SRAM и DRAM
1. Разделить оперативную память на 2 части, операционная система должна сама решать в какую часть лучше класть данные, возникают вопросы доступа к памяти
2. Дать процессору управлять SRAM и поместить его рядом

И правильный вариант - 2. В данном варианте - мы создаем копии данных и помещаем наиболее часто используемые в кэш для работы процессора с ними. Кэш разделяется на кэш для данных и для команд.
1. В случае с данными есть вероятность, что рядом стоящие данные понадобятся в скором времени
2. В случае с командами, например, если у нас в программе в цикле вызывается какая-то функция, то ее вызов помещается в кэш, чтобы n раз не ходить далеко.

![[../Files/Pasted image 20220419044028.png]]

Чем выше уровень, тем больше памяти и ниже скорость.
1. L1d - кэш первого уровня для данных
2. L1i - кэш первого уровня для инструкций

### Как работает кэш-память высокого уровня 
По умолчанию, данные с которыми работает процессор находятся в кэше, за исключением тех, которые нельзя поместить туда, но об этом не стоит думать.

Если процессору требуется  какое-то слово, он сначала ищет его в кэш-памяти, если не находит, идет в основную память и копирует всю линию в L1d. После, изменяет данные, если такую строку обратно не записывают в память - она становится грязной, как только запись произошла, флаг, указывающий на то что она грязная, сбрасывается.

Для того, чтобы в кэш-память можно было загрузить новые данные, почти всегда сначала необходимо освободить место. При удалении из кэш памяти L1d кэш-строка перемещается вниз — в кэш-память L2 (в которой используется тот же самый размер кэш-строки). Конечно, это означает, что в кэш-памяти L2 должно быть место. А это, в свою очередь, может быть причиной перемещения содержимого в кэш-память L3 и, в конце концов, в основную память - эта модель памяти называется эксклюзивной или исключающей моделью. Каждое последующее выталкивание содержимого из кэш-памяти будет все более дорогостоящим.

Есть также инклюзивна или включающая модель при которой слово находящееся в L1d находится одновременно в L2, поэтому удаление из L1d происходит быстро. Преимущество эксклюзивной в том, что кэш-линия загружается только в 1 кэш.

В системах с симметричной многопроцессорной архитектурой(SMP) кэш-память процессоров не может работать независимо, в любой момент времени процессоры должны видеть одно и тоже содержимое памяти. Поддержка этого состояния называется **когерентностью кэша**. Если процессор видит свою собственную кэш-память и основную память, он не должен видеть содержимое грязных кэш-строк в других процессорах. Реализация прямого доступа к кэш-памяти одного процессора из другого процессора является чрезвычайно дорогой и чрезвычайно узкой по производительности. Вместо этого, процессоры просто узнают, когда другой процессор хочет прочитать или записать определенную кэш-строку.

Если обнаружен доступ на запись и у процессора в его кэш-памяти есть просто копия кэш-строки, то эта кэш-строка помечается как неверная. Будущие обращения к ней потребуют ее перезагрузки. Обратите внимание, что доступ на чтение из другого процессора не потребует помечать ее как неверную, так что вполне может быть сразу несколько чистых копий кэш-строки.

### Запись данных
Есть два варианта записи изменений кэша:
1. Прямая запись - если изменяется кэш линия, то процессора сразу изменяет и данные в основной памяти, не очень эффективно, т.к. при каждом изменении придется изменять данные в памяти.
2. Обратная запись - если изменяется кэш линия, данные не сразу изменяются в основной памяти, линия помечается как измененная, если она удаляется из кэша с флагом измененности, то процессора записывает обновленные данные в основную память. Проблема в том, что если у нас есть несколько процессоров или ядер, нужно обеспечить доступ в обновленным кэш данным всем процессам.

Для реализации обратной записи разработали протокол MESI - протокол назван в честь 4 состояний кэш линии:
1. Modified - Модифицированный - локальный процессора изменил кэш линию, подразумевается, что в кэше находится только одна копия кэш линии
2. Exclusive - Эксклюзивный - кэш-линия не изменена, но известно, что она не загружена ни в какую-либо кэш-память другого процессора
3. Shared - Разделяемый - кэш-линия не изменена,  но она может быть в кэш-памяти какого-нибудь другого процессора
4. Invalid - Недействительный - кэш-линия недействительная, т.е. не используется.

![[../Files/Pasted image 20220419125929.png]]

Изменение состояний происходит без особых затрат за счет прослушивания или перехвата сигналов, что выполняется другими процессорами. Некоторые операции, которые выполняет процессор, анонсируются на внешних контактах и, следовательно, за пределами процессора становится известно о том, как происходит обработка кэш-памяти процессора.

1. Первоначально все кэш-строки пусты, а, следовательно, и недействительны (состояние Invalid). 
2. Если данные будут загружены для записи, то кэш-строка станет модифицированной. 
3. Если данные загружаются для чтения, то новое состояние зависит от того, будет ли та же кэш-строка также загружена другим процессором. 
	1. Если будет, то процессор отправляет другому процессору кэш-линию, новое состояние будет разделяемым
	2. В противном случае - эксклюзивным.
4. Если второй процессор хочет изменить кэш-линию, то первый процессор посылается кэш-линию и локально помечает кэш-линию как недействительную - эта операция называется  Request For Ownership(RFO) - выполнение этой операции в кэше последнего уровня является дорогим.
5. Если кэш-линия находится в разделяемом состоянии и локальный процессор выполняет чтение, то нет необходимости изменять состояние.
	1. Если в кэш-линии происходит локальная запись, то кэш-линия может использоваться, но ее состояние изменится на модифицированное, при этом все копии кэш-линии в других процессорах помечаются как недействительные. Таким образом, операция записи с помощью сообщения RFO должна оповестить другие процессоры об инвалидации кэш-линии
6. Эксклюзивное состояние идентично разделяемому состоянию с одним отличием - сообщения о локальных операциях записи не должны передаваться по шине

Есть две ситуации, когда необходимы сообщения RFO:
1. Поток мигрирует с одного процессора на другой, и все кэш-строки должны быть сразу перенесены на новый процессор.
2. Кэш-строка действительно необходима в двух разных процессорах. В меньшей степени то же самое верно для двух ядер на одном процессоре. Затраты только немного меньше. Вероятно, что сообщение RFO будет отправляться много раз.

#do/review https://www.youtube.com/watch?v=7n_8cOBpQrg
https://www.youtube.com/c/АПСПопов/videos
https://github.com/MPSU/APS-info

### Кэш и многопоточность
#do/start найти инфу

Исходим из расчета, что занимается по 10 часов в день
1. Параллельно изучаем Операционки(2 курса) и Юзотуса шаблоны, т.е. пол дня одно, пол дня другое 35 + 50 часов = 85 часов - примерно 9 дней
2. Математика, конспектируем лекции Дашкова + комбинаторика Виленкин в тетрадь, так же параллельно - 120 часов - 12 дней
3. Грокаем алгоритмы - 70 часов - 7 дней
4. Что-то еще по алгосам
5. Формальные языки - 45 часов + в конце дня часа 4 уделять Сюзанне - 8 дней
6. Тулчейн ГЦЦ - 16 часов + 5 часов Сюзанне - 3 дня
7. Базовый Костик - 66 часов + 4 часа Сюзанне - 11 дней
8. Проекты - аллокатор, сборщик мусора. 4 дня
9. Многопоток - 124 часа + 4 часа Сюзанне - 20 дней

По сути, не везде требуется многопоток и после проектов можно искать работу параллельно изучая многопоток, я думаю. Без многопотока все займет 44 дней, если по алгосам ничего не добавлю. С многопотоком +15 дней.

То есть если уделять по 12 часов в день, ежедневно, что довольно сложно, я успею к началу июня без многопотока