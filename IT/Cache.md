# Cache
Доступ к [[Primary memory|оперативной памяти]] занимает какое-то время, во время которого процессор простаивает, для лучше работоспособности придумали кэш - память которая находится рядом с процессором.

![[../Files/Pasted image 20220419041047.png]]

Какие есть варианты использования SRAM и DRAM
1. Разделить оперативную память на 2 части, операционная система должна сама решать в какую часть лучше класть данные, возникают вопросы доступа к памяти
2. Дать процессору управлять SRAM и поместить его рядом

И правильный вариант - 2. В данном варианте - мы создаем копии данных и помещаем наиболее часто используемые в кэш для работы процессора с ними. Кэш разделяется на кэш для данных и для команд.
1. В случае с данными есть вероятность, что рядом стоящие данные понадобятся в скором времени
2. В случае с командами, например, если у нас в программе в цикле вызывается какая-то функция, то ее вызов помещается в кэш, чтобы n раз не ходить далеко.

![[../Files/Pasted image 20220419044028.png]]

Чем выше уровень, тем больше памяти и ниже скорость.
1. L1d - кэш первого уровня для данных
2. L1i - кэш первого уровня для инструкций

# Как работает кэш-память высокого уровня 
По умолчанию, данные с которыми работает процессор находятся в кэше, за исключением тех, которые нельзя поместить туда.

Если процессору требуется  какое-то слово, он сначала ищет его в кэш-памяти, если не находит, идет в основную память и копирует всю линию в L1d. После, изменяет данные, если такую строку обратно не записывают в память - она становится грязной, как только запись произошла, флаг, указывающий на то что она грязная, сбрасывается.

Для того, чтобы в кэш-память можно было загрузить новые данные, сначала необходимо освободить место. При удалении из кэш-памяти L1d кэш-строка перемещается вниз — в кэш-память L2 (в которой используется тот же самый размер кэш-строки), из $L2=>L3$  и, из $L3=>$ в основную память - эта модель памяти называется эксклюзивной или исключающей моделью. Каждое последующее выталкивание содержимого из кэш-памяти будет все более дорогостоящим.

Есть также инклюзивная или включающая модель при которой слово находящееся в L1d находится одновременно в L2, поэтому удаление из L1d происходит быстро. Преимущество эксклюзивной в том, что кэш-линия загружается только в 1 кэш.

# Когерентность кэша
Если у нас многопроцессорная архитектура, и два процессора кладут в кэш одни и те же данные, они должны договариваться между собой об использовании данных, иначе может получиться, типичная ситуация из многопоточного программирования, когда 2 процессора берут одни и те же данные, а после сначала один процессор возвращает измененные данные в память, а потом другой. Чтобы такого не происходило, придумали **протоколы и механизмы когерентности.**

## Механизмы когерентности
Два самых известных механизма когерентности это snooping и использование директорий(directory-based), у каждого из них есть преимущества и недостатки.

### Snooping
Каждый запрос передается (broadcast) всем другим узлам. Протоколы, базирующиеся на этом механизме, быстрее, если у шины достаточная пропускная способность, т.к. все запросы/ответы видны всем процессорам. Недостаток в том, что такие системы плохо масштабируются. Каждый запрос должен передаваться всем узлам сети, а это значит, что вся система становится больше, ширина шины и ее пропускная способность тоже должны увеличиваться.

### Использование директорий
При таком механизме, общие данные хранятся в специальной общей директории, которая и решает проблему когерентности: при запросе на чтение процессор должен спросить разрешение у директории на то, чтобы загрузить данные из памяти себе в кэш. Если процессор изменяет кэш-линию, то директория либо обновляет данные других кэшей, либо говорит им выкинуть свои копии. Директории медленнее, но не нуждаются в широкой шине, т.к. сообщения передаются от одного узла к другому, а не всем узлам сети. По этой причине многие многопроцессорные системы (>64 CPU) используют именно этот механизм.

## Протоколы когерентности
### MSI
1. Modified - кэш-линия была изменена, т.е. данные в кэше не совпадают с данными в памяти. Кэш несет ответственность за запись такой линии в память. 
2. Shared - кэш-линия не изменена и присутствует в read-only состоянии хотя бы в одном кэше. Кэш может выкинуть такую линию без записи в память.
3. Invalid - кэш-линия или не присутствует в данном кэше, или была аннулирована запросом шины.

**В CPU0_Cache пришел запрос на чтение кэш-линия X:**
1. Если X Modified или Shared, CPU0_Cache возвращает кэш-линиюX, и всё хорошо
2. Если же X Invalid, то CPU0_Cache должен выяснить, не находится ли эта линия где-то в другом кэше в состоянии Modified
	1. Если в CPUN_Cache линия X находится в состоянии Modified, он должен записать эту кэш-линию в память и перевести её в состояние Shared или Invalid. После этого CPU0_Cache считывает кэш-линию X из памяти или у кэша, у которого блок в состоянии Shared.
	2. Если в CPUN_Cache кэш-линия X находится в состоянии Shared, CPU0_Cache получает кэш-линию от CPUN_Cache
	3. Если ни в одном другом кэше нет линии X, кэш обращается к памяти.

После операции чтения кэш-линия X в CPU0_Cache находится в состоянии Shared.

**В CPU0_Cache пришел запрос на запись в кэш-линию X:**
1. Если кэш-линия в состоянии Modified, кэш изменяет её локально и всё у него хорошо.
2. Если кэш-линия в состоянии Shared, то кэш говорит всем остальным выкинуть свои копии. Далее данные могут быть изменены локально.
3. Если кэш-линия в состоянии Invalid, то кэш должен сообщить всем остальным кэшам выкинуть свои копии. Если в каком-то из кэшей линия в состоянии Modified, то этот кэш может как записать кэш-линию в память, так и передать её CPU0_Cache. Это зависит от реализации. Если на этот момент CPU0_Cache еще не получил кэш-линию X, он запрашивает её у памяти.

После операции записи кэш-линия X в CPU0_Cache находится в состоянии Modified.

![[../Files/Pasted image 20220517200542.png]]

Чаще всего у процессора какие-то свои данные, которые есть только у него. Тем не менее, каждый раз, когда ему надо сделать запись в Shared, он держит в курсе остальных, что надо бы эти данные выкинуть. Шина забивается мусорными сообщениями.

### MESI
1. Modified - Модифицированный - локальный процессора изменил кэш линию, подразумевается, что в кэше находится только одна копия кэш линии
2. Exclusive - Эксклюзивный - кэш-линия не изменена, но известно, что она не загружена ни в какую-либо кэш-память другого процессора
3. Shared - Разделяемый - кэш-линия не изменена,  но она может быть в кэш-памяти какого-нибудь другого процессора
4. Invalid - Недействительный - кэш-линия недействительная, т.е. не используется.

![[../Files/Pasted image 20220517200917.png]]

Когда несколько процессоров пишут в одну и ту же кэш-линию, ее постоянно приходится сбрасывать в память. А еще когда процессор запрашивает линию, которая в нескольких других находится в состоянии Shared, то отвечают все и забивают шину

![[../Files/Pasted image 20220419125929.png]]

Изменение состояний происходит без особых затрат за счет прослушивания или перехвата сигналов, что выполняется другими процессорами. Некоторые операции, которые выполняет процессор, анонсируются на внешних контактах и, следовательно, за пределами процессора становится известно о том, как происходит обработка кэш-памяти процессора.

1. Первоначально все кэш-строки пусты, а, следовательно, и недействительны (состояние Invalid). 
2. Если данные будут загружены для записи, то кэш-строка станет модифицированной. 
3. Если данные загружаются для чтения, то новое состояние зависит от того, будет ли та же кэш-строка также загружена другим процессором. 
	1. Если будет, то процессор отправляет другому процессору кэш-линию, новое состояние будет разделяемым
	2. В противном случае - эксклюзивным.
4. Если второй процессор хочет изменить кэш-линию, то первый процессор посылается кэш-линию и локально помечает кэш-линию как недействительную - эта операция называется  Request For Ownership(RFO) - выполнение этой операции в кэше последнего уровня является дорогим.
5. Если кэш-линия находится в разделяемом состоянии и локальный процессор выполняет чтение, то нет необходимости изменять состояние.
	1. Если в кэш-линии происходит локальная запись, то кэш-линия может использоваться, но ее состояние изменится на модифицированное, при этом все копии кэш-линии в других процессорах помечаются как недействительные. Таким образом, операция записи с помощью сообщения RFO должна оповестить другие процессоры об инвалидации кэш-линии
6. Эксклюзивное состояние идентично разделяемому состоянию с одним отличием - сообщения о локальных операциях записи не должны передаваться по шине

Есть две ситуации, когда необходимы сообщения RFO:
1. Поток мигрирует с одного процессора на другой, и все кэш-строки должны быть сразу перенесены на новый процессор.
2. Кэш-строка действительно необходима в двух разных процессорах. В меньшей степени то же самое верно для двух ядер на одном процессоре. Затраты только немного меньше. Вероятно, что сообщение RFO будет отправляться много раз.

### MOESI
Это вариация AMD на тему MESI. Теперь
1. Owned - этот кэш один из нескольких, у кого есть копия этой кэш-линии, но только он может вносить изменения. Состояние Owned позволяет делиться измененными кэш-линиями, не записывая изменения в память. Кэш-линия может быть переведена в состояние Modified, после того, как все остальные кэши выкинут свои копии, и в состояние Shared, после записи изменений в память.
2. Shared - эта кэш-линия - одна из нескольких копий в системе. Кэш не может вносить изменения в эту кэш-линию. Линия может как совпадать с памятью (ни у одного кэша нет этой линии в состоянии Owned), так и быть измененной (где-то есть кэш, у которого эта кэш-линия Owned). Кэш-линия может быть переведена в состояние Modified или Exclusive, после того, как остальные кэши выкинут свои копии.

![[../Files/Pasted image 20220517201231.png]]

Из-за того, что не можем не писать измененные данные в память, получаем выигрыш по скорости, если шина от кэша до процессора сильно жирнее и быстрее, чем от кэша до памяти.

Не можем быстро читать чистые (неизмененные) линии. Если у каких-то двух кэшей есть линия в состоянии Shared, и она не изменена, то третий скорее получит эту линию от памяти, чем от кэшей.

### MESIF
Вариация Intel на тему MESI. Теперь:
1. Forward - специальный вид состояния Shared, показывает, что кэш должен отвечать на запросы шины по этой кэш-линии.

В итоге, не загружаем шину ответами кэшей.

# Кеширование данных
Если бы кэш кэшировал побайтово, то вместе с каждыми 8 битами данных мы хранили бы еще 32 бита адреса. Не очень выгодно, особенно учитывая что кэш - дорогое удовольствие (занимает до четверти кристалла). Данные кэшируются кэш-линиями. Обычно одна кэш-линия - 64 байта. Соответственно адрес можно хранить один на кэш-линию. Кэш-линии не пересекаются! Т.е. адрес кэш-линии должен быть кратен 64. Следовательно можем не хранить для линии младшие 6 бит адреса - это всё равно нули.

![[cachetoc.excalidraw]]
Как-то так разделяется адрес. Offset - адрес данных внутри кэш-линии.

## Политика кеширования
Поиск кэш-линии ведется по тэгу (блок T в адресе). Существует несколько способов организовать адрес.

### Полная ассоциативность 
Можем любой блок данных положить в любую строку кэша. Т.е. размер блока  $S=0$. Это значит, что нам нужно провести $2^T$ сравнений, где $T$ - размер тэга. Это очень много. Мы не можем делать сравнения последовательно (это долго, следовательно теряется весь смысл кэша), значит нам нужно $2^T$ аппаратных компараторов. Что-то многовато

### Direct-mapping 
Другая крайность: пусть теперь размер тэга равен нулю. Встречаем другую проблему: если мы обращаемся к блокам памяти, которые попадают в одну кэш-линию, то работа с ними получается даже немного медленнее, чем без кэша: мы постоянно вытесняем одни данные другими.

### Групповая ассоциативность 
Разделим кэш на N групп по M кэш-линий в каждой. Пусть поступил запрос с адресом ячейки X. Последние O ячеек - адрес внутри кэшлинии. Следующие с конца log N бит - адрес группы. Внутри группы ищем кэш-линию по тэгу. Сейчас в основном распространена 8-ассоциативность.

# Когда кэш полезен? 
Идея кэша опирается на идею пространственно-временной локальности (в близкие промежутки времени обращаемся к близко лежащим данным). Соответственно если алгоритм эту идею не использует (обращается к памяти более-менее случайно), то кэш не особенно поможет

# Кэш миссы
```cpp
for i = 0..n:				for i=0..n:
    for j=0..n:				for j=0..n:
        a[i][j] = 0 				a[j][i] = 0

```
У этих двух кодов большая разница из-за процессорного кэша. Первый цикл обращается к памяти последовательно, а второй "скачет" по ней. Поэтому обращения к памяти первого цикла попадают в кэш, а второго - нет. С ростом **N** видна разница между уровнями кэша на графике времени обработки одного элемента:
![](02.29_cache_hit_graph.png)
![[../Files/Pasted image 20220517153333.png]]

Небольшие пики - скачки из-за попадания в один бакет (заметно на степенях двойки), сильное изменение времени работы происходит, когда данные перестают попадать в кэш какого-то уровня.

**Кэш** реализован через хэш-таблицы (дискретного размера), где ключ - адрес в памяти. Линии кэша примерно по _64 байта_ разделенные на группы (buckets), размеры которых называются ассоциативностью кэша.

**Prefetching** - если много кэш-промахов, запрашиваем заранее подгрузить в кэш. Это работает на уровне кэш-подсистемы процессора, а не компилятора/ОС.

_Пример_: хранение хэш-таблицы с открытой адресацией. Два варианта:
![](02.29_hash_table.png)
-   Если ожидаются частые попадания, то хранить полезнее данные рядом с ключом.
-   Если ожидаются редкие попадания, то лучше хранить ключи и данные отдельно.

# Конвейер (Pipelining)
Разбили выполнение команды на несколько стадий, теперь можем повысить частоту, так как каждая стадия стала проще. Выигрыш в том, что можем давать новые данные на каждом такте.

**Спекулятивное исполнение**: условные переходы дорогие, поэтому мы предсказываем переход, выполняем, а если не угадали, то откатываемя. В общем, ничего нового. Также это называется **branch prediction**. Можем как выиграть, так и проиграть от этого. Например, [в некоторых программах на отсортированном массиве](https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array) предсказание может улучшить время работы в несколько раз.

Полезно писать программу так, чтобы уровень зависимостей команд был как можно меньше (это может также пытаться делать компилятор). Например:

`int f(int a, int b, int c, int d) {  return a * b * c * d; }`

может скомпилиться в следующий код, чтоб уменьшить количество зависимых умножений: $(a * b) * (c * d)$
```asm
 imul edi, esi
 imul edx, ecx  
 imul edx, edi  
 mov	 eax, edx  
 ret
```

Похожее происходит с циклами. Посмотрим на алгоритм Хаффмана:
```cpp
void count_huffman_weights(char const* src, size_t size) {      
	uint32_t count[256] = {0};      
	for (size_t i = 0; i != size; ++i)          
		++count[src[i]]; 
}
```


может быть разбит компилятором на параллельные исполнения. Так будут выглядеть зависимости:

![](02.29_dependencies.png)

Но у нас возникают проблемы из-за того, что мы пишем в одни переменные. Как пофиксить? Можем сделать 8 разных массивов-счетчиков. Такая реализация используется в библиотеке **Zstandart**

```cpp
void count_huffman_weights_improved(char const* src, size_t size) {  
	uint32_t count[8][256] = {};  
	size = size / 8 * 8;  
	for (size_t i = 0; i < size;){            
		++count[0][src[i++]]; ++count[1][src[i++]]; ++count[2][src[i++]];            
		++count[3][src[i++]]; ++count[4][src[i++]]; ++count[5][src[i++]];            
		++count[6][src[i++]]; ++count[7][src[i++]];      
	} 
}
```